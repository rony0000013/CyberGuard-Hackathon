{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, wandb\n",
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pl.read_csv(\"train.csv\")\n",
    "test = pl.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.with_columns(pl.col(\"category\").str.to_lowercase(), \n",
    "                    pl.col(\"sub_category\").str.to_lowercase().fill_null(\"NULL\"), \n",
    "                    pl.col(\"crimeaditionalinfo\").str.to_lowercase().str.strip_chars())\n",
    "test = test.with_columns(pl.col(\"category\").str.to_lowercase(), \n",
    "                    pl.col(\"sub_category\").str.to_lowercase().fill_null(\"NULL\"), \n",
    "                    pl.col(\"crimeaditionalinfo\").str.to_lowercase().str.strip_chars())\n",
    "train = train.with_columns((pl.struct([\"category\", \"sub_category\"])\n",
    "                    .map_elements(lambda e: e[\"category\"] + \" - \" + e[\"sub_category\"], return_dtype=pl.String))\n",
    "                    .alias(\"output\"))\n",
    "test = test.with_columns((pl.struct([\"category\", \"sub_category\"])\n",
    "                    .map_elements(lambda e: e[\"category\"] + \" - \" + e[\"sub_category\"], return_dtype=pl.String))\n",
    "                    .alias(\"output\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Null text use category = \"online financial fraud\",  sub_category = \"upi related frauds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.filter(pl.col(\"len\").is_null()).group_by([\"category\", \"sub_category\"]).len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.filter(pl.col(\"crimeaditionalinfo\").is_not_null())\n",
    "test = test.filter(pl.col(\"crimeaditionalinfo\").is_not_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "x = le.fit_transform(train[\"output\"])\n",
    "train = train.insert_column(4, pl.Series(name=\"label\", values=x))\n",
    "le.classes_ = np.append(le.classes_, \"NULL\")\n",
    "\n",
    "x = le.transform([\"NULL\" if x not in le.classes_ else x for x in test[\"output\"]])\n",
    "test = test.insert_column(4, pl.Series(name=\"label\", values=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/miniforge3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06dd3be93f8f446c8cada5e83d392e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/93665 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e3376a9864b48f88ad10e2417ae155c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10303 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "train_dataset = Dataset.from_polars(train)\n",
    "test_dataset = Dataset.from_polars(test.sample(fraction=0.33))\n",
    "\n",
    "def tokenize_data(examples):\n",
    "    return tokenizer(examples[\"crimeaditionalinfo\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize_data, batched=True)\n",
    "tokenized_test = test_dataset.map(tokenize_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202aa52679834893a8b43a9eb3cd1d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112998899999284, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/student/hackathon/wandb/run-20241107_002402-fhskdnh1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rony00013/Govt%20Hackathon/runs/fhskdnh1' target=\"_blank\">robust-planet-6</a></strong> to <a href='https://wandb.ai/rony00013/Govt%20Hackathon' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rony00013/Govt%20Hackathon' target=\"_blank\">https://wandb.ai/rony00013/Govt%20Hackathon</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rony00013/Govt%20Hackathon/runs/fhskdnh1' target=\"_blank\">https://wandb.ai/rony00013/Govt%20Hackathon/runs/fhskdnh1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project='Govt Hackathon', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(le.classes_)).to(device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.1,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5854' max='5854' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5854/5854 5:31:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>1.242800</td>\n",
       "      <td>1.680815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1172</td>\n",
       "      <td>2.273300</td>\n",
       "      <td>1.677860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1758</td>\n",
       "      <td>2.023800</td>\n",
       "      <td>1.598853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2344</td>\n",
       "      <td>1.274400</td>\n",
       "      <td>1.591804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>2.147800</td>\n",
       "      <td>1.601974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3516</td>\n",
       "      <td>1.341100</td>\n",
       "      <td>1.596113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4102</td>\n",
       "      <td>1.185500</td>\n",
       "      <td>1.507481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4688</td>\n",
       "      <td>1.366500</td>\n",
       "      <td>1.494886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5274</td>\n",
       "      <td>1.626700</td>\n",
       "      <td>1.481625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5854, training_loss=1.6473084893351249, metrics={'train_runtime': 19904.5481, 'train_samples_per_second': 4.706, 'train_steps_per_second': 0.294, 'total_flos': 5243773357673088.0, 'train_loss': 1.6473084893351249, 'epoch': 0.9999145956102143})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60ed5b5e3f84d52b951200fdc761cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.016 MB of 0.016 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▅▅▅▅▂▁▁</td></tr><tr><td>eval/runtime</td><td>█▄▅▁▁▅▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▅▄██▄███</td></tr><tr><td>eval/steps_per_second</td><td>▁▅▄██▄███</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▃▁▁▁▂▁▂▁▂▂▂█▁▁▁▁▄▁▂▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▇▇▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▇▃█▅▆▄▃█▅▂▆▅▄▂▂▃▃▂▆▆▄▄▅▄▁▃▄▄▆▄▄▄▅▅▄▃▄▆▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.48163</td></tr><tr><td>eval/runtime</td><td>540.765</td></tr><tr><td>eval/samples_per_second</td><td>19.053</td></tr><tr><td>eval/steps_per_second</td><td>2.382</td></tr><tr><td>total_flos</td><td>5243773357673088.0</td></tr><tr><td>train/epoch</td><td>0.99991</td></tr><tr><td>train/global_step</td><td>5854</td></tr><tr><td>train/grad_norm</td><td>5.32764</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6912</td></tr><tr><td>train_loss</td><td>1.64731</td></tr><tr><td>train_runtime</td><td>19904.5481</td></tr><tr><td>train_samples_per_second</td><td>4.706</td></tr><tr><td>train_steps_per_second</td><td>0.294</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">robust-planet-6</strong> at: <a href='https://wandb.ai/rony00013/Govt%20Hackathon/runs/fhskdnh1' target=\"_blank\">https://wandb.ai/rony00013/Govt%20Hackathon/runs/fhskdnh1</a><br/> View project at: <a href='https://wandb.ai/rony00013/Govt%20Hackathon' target=\"_blank\">https://wandb.ai/rony00013/Govt%20Hackathon</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241107_002402-fhskdnh1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.save_model('model/distillbert_finetuned_1')\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('model/distillbert_finetuned_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"model/distillbert_finetuned_1\", num_labels=len(le.classes_))\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/distillbert_finetuned_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7bad07783541faa96da6a2fa56055a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Making predictions:   0%|          | 0/31222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5348\n"
     ]
    }
   ],
   "source": [
    "def predict_text(text, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Process single text input and return predicted class\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    return logits.argmax().item()\n",
    "\n",
    "def evaluate_model(test_df, model, tokenizer):\n",
    "    \"\"\"\n",
    "    Evaluate model on test dataset\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    # Use tqdm progress bar for iteration\n",
    "    for text in tqdm(test_df['crimeaditionalinfo'], desc=\"Making predictions\"):\n",
    "        pred = predict_text(text, model, tokenizer)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_df['label'], predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "results = evaluate_model(test.to_pandas(), model, tokenizer)\n",
    "test.with_columns(pl.Series(\"result\", results[\"predictions\"]))\n",
    "\n",
    "test.write_csv(\"result.csv\")\n",
    "print(f\"Model Accuracy: {results['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
